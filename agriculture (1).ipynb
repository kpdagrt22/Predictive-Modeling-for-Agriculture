{"cells":[{"source":"# Sowing Success: How Machine Learning Helps Farmers Select the Best Crops\n\n![Farmer in a field](farmer_in_a_field.jpg)\n\nMeasuring essential soil metrics such as nitrogen, phosphorous, potassium levels, and pH value is an important aspect of assessing soil condition. However, it can be an expensive and time-consuming process, which can cause farmers to prioritize which metrics to measure based on their budget constraints.\n\nFarmers have various options when it comes to deciding which crop to plant each season. Their primary objective is to maximize the yield of their crops, taking into account different factors. One crucial factor that affects crop growth is the condition of the soil in the field, which can be assessed by measuring basic elements such as nitrogen and potassium levels. Each crop has an ideal soil condition that ensures optimal growth and maximum yield.\n\nA farmer reached out to you as a machine learning expert for assistance in selecting the best crop for his field. They've provided you with a dataset called `soil_measures.csv`, which contains:\n\n- `\"N\"`: Nitrogen content ratio in the soil\n- `\"P\"`: Phosphorous content ratio in the soil\n- `\"K\"`: Potassium content ratio in the soil\n- `\"pH\"` value of the soil\n- `\"crop\"`: categorical values that contain various crops (target variable).\n\nEach row in this dataset represents various measures of the soil in a particular field. Based on these measurements, the crop specified in the `\"crop\"` column is the optimal choice for that field.  \n\nIn this project, you will build multi-class classification models to predict the type of `\"crop\"` and identify the single most importance feature for predictive performance.","metadata":{},"id":"d3d001b0-2e2f-4b58-8442-99520bad831f","cell_type":"markdown"},{"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset\ndata = pd.read_csv('soil_measures.csv')\n\n# Encode the target variable (crop)\nlabel_encoder = LabelEncoder()\ndata['crop_encoded'] = label_encoder.fit_transform(data['crop'])\n\n# Features to evaluate\nfeatures = ['N', 'P', 'K', 'ph']\nX = data[features]\ny = data['crop_encoded']\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=features)\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Dictionary to store accuracy scores\naccuracy_scores = {}\n\n# Train and evaluate a logistic regression model for each feature\nfor feature in features:\n    # Train model using a single feature\n    model = LogisticRegression(multi_class='multinomial', random_state=42, max_iter=1000)\n    model.fit(X_train[[feature]], y_train)\n    \n    # Predict on test set\n    y_pred = model.predict(X_test[[feature]])\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_scores[feature] = accuracy\n    \n    # Print classification report for additional metrics\n    print(f\"\\nClassification Report for {feature}:\")\n    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))\n\n# Identify the best feature\nbest_feature = max(accuracy_scores, key=accuracy_scores.get)\nbest_score = accuracy_scores[best_feature]\n\n# Create the output dictionary\nbest_predictive_feature = {best_feature: best_score}\n\n# Print results\nprint(\"\\nAccuracy Scores for Each Feature:\")\nfor feature, score in accuracy_scores.items():\n    print(f\"{feature}: {score:.4f}\")\nprint(\"\\nBest Predictive Feature:\")\nprint(best_predictive_feature)","metadata":{"id":"bA5ajAmk7XH6","executionTime":2020,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset\ndata = pd.read_csv('soil_measures.csv')\n\n# Encode the target variable (crop)\nlabel_encoder = LabelEncoder()\ndata['crop_encoded'] = label_encoder.fit_transform(data['crop'])\n\n# Features to evaluate\nfeatures = ['N', 'P', 'K', 'ph']\nX = data[features]\ny = data['crop_encoded']\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=features)\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Dictionary to store accuracy scores\naccuracy_scores = {}\n\n# Train and evaluate a logistic regression model for each feature\nfor feature in features:\n    # Train model using a single feature\n    model = LogisticRegression(multi_class='multinomial', random_state=42, max_iter=1000)\n    model.fit(X_train[[feature]], y_train)\n    \n    # Predict on test set\n    y_pred = model.predict(X_test[[feature]])\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_scores[feature] = accuracy\n    \n    # Print classification report for additional metrics\n    print(f\"\\nClassification Report for {feature}:\")\n    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))\n\n# Identify the best feature\nbest_feature = max(accuracy_scores, key=accuracy_scores.get)\nbest_score = accuracy_scores[best_feature]\n\n# Create the output dictionary\nbest_predictive_feature = {best_feature: best_score}\n\n# Print results\nprint(\"\\nAccuracy Scores for Each Feature:\")\nfor feature, score in accuracy_scores.items():\n    print(f\"{feature}: {score:.4f}\")\nprint(\"\\nBest Predictive Feature:\")\nprint(best_predictive_feature)","executionCancelledAt":null,"lastExecutedAt":1749118985849,"lastScheduledRunId":null,"lastExecutedByKernel":"c84071fa-0cc3-479d-be52-90084b1ae31b","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"\nClassification Report for N:\n              precision    recall  f1-score   support\n\n       apple       0.00      0.00      0.00        23\n      banana       0.00      0.00      0.00        21\n   blackgram       0.08      0.25      0.12        20\n    chickpea       0.00      0.00      0.00        26\n     coconut       0.00      0.00      0.00        27\n      coffee       0.07      0.12      0.09        17\n      cotton       0.32      0.71      0.44        17\n      grapes       0.06      0.29      0.11        14\n        jute       0.00      0.00      0.00        23\n kidneybeans       0.00      0.00      0.00        20\n      lentil       0.06      0.64      0.11        11\n       maize       0.31      0.24      0.27        21\n       mango       0.00      0.00      0.00        19\n   mothbeans       0.00      0.00      0.00        24\n    mungbean       0.00      0.00      0.00        19\n   muskmelon       0.19      0.18      0.18        17\n      orange       0.00      0.00      0.00        14\n      papaya       0.38      0.57      0.46        23\n  pigeonpeas       0.00      0.00      0.00        23\n pomegranate       0.27      0.13      0.18        23\n        rice       0.24      0.47      0.32        19\n  watermelon       0.25      0.16      0.19        19\n\n    accuracy                           0.15       440\n   macro avg       0.10      0.17      0.11       440\nweighted avg       0.10      0.15      0.11       440\n\n\nClassification Report for P:\n              precision    recall  f1-score   support\n\n       apple       0.00      0.00      0.00        23\n      banana       0.42      0.76      0.54        21\n   blackgram       0.00      0.00      0.00        20\n    chickpea       0.00      0.00      0.00        26\n     coconut       0.00      0.00      0.00        27\n      coffee       0.17      0.53      0.26        17\n      cotton       0.16      0.65      0.26        17\n      grapes       0.38      1.00      0.55        14\n        jute       0.00      0.00      0.00        23\n kidneybeans       0.00      0.00      0.00        20\n      lentil       0.08      0.55      0.14        11\n       maize       0.00      0.00      0.00        21\n       mango       0.00      0.00      0.00        19\n   mothbeans       0.00      0.00      0.00        24\n    mungbean       0.08      0.05      0.06        19\n   muskmelon       0.00      0.00      0.00        17\n      orange       0.12      0.64      0.20        14\n      papaya       0.11      0.30      0.16        23\n  pigeonpeas       0.00      0.00      0.00        23\n pomegranate       0.00      0.00      0.00        23\n        rice       0.00      0.00      0.00        19\n  watermelon       0.00      0.00      0.00        19\n\n    accuracy                           0.17       440\n   macro avg       0.07      0.20      0.10       440\nweighted avg       0.06      0.17      0.08       440\n\n\nClassification Report for K:\n              precision    recall  f1-score   support\n\n       apple       0.00      0.00      0.00        23\n      banana       0.00      0.00      0.00        21\n   blackgram       0.00      0.00      0.00        20\n    chickpea       1.00      1.00      1.00        26\n     coconut       0.00      0.00      0.00        27\n      coffee       0.32      0.82      0.46        17\n      cotton       0.00      0.00      0.00        17\n      grapes       0.38      1.00      0.55        14\n        jute       0.00      0.00      0.00        23\n kidneybeans       0.00      0.00      0.00        20\n      lentil       0.07      0.73      0.13        11\n       maize       0.00      0.00      0.00        21\n       mango       0.00      0.00      0.00        19\n   mothbeans       0.00      0.00      0.00        24\n    mungbean       0.00      0.00      0.00        19\n   muskmelon       0.17      1.00      0.29        17\n      orange       0.21      1.00      0.35        14\n      papaya       0.00      0.00      0.00        23\n  pigeonpeas       0.00      0.00      0.00        23\n pomegranate       0.00      0.00      0.00        23\n        rice       0.29      0.79      0.43        19\n  watermelon       0.00      0.00      0.00        19\n\n    accuracy                           0.25       440\n   macro avg       0.11      0.29      0.15       440\nweighted avg       0.11      0.25      0.14       440\n\n\nClassification Report for ph:\n              precision    recall  f1-score   support\n\n       apple       0.00      0.00      0.00        23\n      banana       0.00      0.00      0.00        21\n   blackgram       0.00      0.00      0.00        20\n    chickpea       0.24      0.42      0.31        26\n     coconut       0.00      0.00      0.00        27\n      coffee       0.00      0.00      0.00        17\n      cotton       0.00      0.00      0.00        17\n      grapes       0.08      0.57      0.14        14\n        jute       0.00      0.00      0.00        23\n kidneybeans       0.00      0.00      0.00        20\n      lentil       0.04      0.27      0.06        11\n       maize       0.00      0.00      0.00        21\n       mango       0.15      0.58      0.23        19\n   mothbeans       0.00      0.00      0.00        24\n    mungbean       0.00      0.00      0.00        19\n   muskmelon       0.09      0.41      0.15        17\n      orange       0.03      0.07      0.05        14\n      papaya       0.00      0.00      0.00        23\n  pigeonpeas       0.00      0.00      0.00        23\n pomegranate       0.00      0.00      0.00        23\n        rice       0.00      0.00      0.00        19\n  watermelon       0.07      0.11      0.08        19\n\n    accuracy                           0.10       440\n   macro avg       0.03      0.11      0.05       440\nweighted avg       0.03      0.10      0.05       440\n\n\nAccuracy Scores for Each Feature:\nN: 0.1500\nP: 0.1659\nK: 0.2455\nph: 0.0977\n\nBest Predictive Feature:\n{'K': 0.24545454545454545}\n"}]},{"source":"Explanation of the Code\nData Loading: The dataset is loaded using pd.read_csv. It contains 2200 rows with columns N, P, K, pH, and crop (22 unique crop types).\nLabel Encoding: The crop column is encoded into numerical labels (0–21) using LabelEncoder.\nFeature Scaling: Features are standardized using StandardScaler to ensure logistic regression performs optimally, as it is sensitive to feature scales.\nTrain-Test Split: The data is split into 80% training (1760 rows) and 20% testing (440 rows) sets with a fixed random_state=42 for reproducibility.\nModel Training: A logistic regression model is trained for each feature individually, using the multinomial setting for multi-class classification and max_iter=1000 to ensure convergence.\nEvaluation:\nAccuracy: Computed using accuracy_score to measure the proportion of correctly predicted crop types.\nClassification Report: Provides precision, recall, and F1-score (weighted averages) for each feature’s model, handling cases where some classes may have zero predictions with zero_division=0.\nBest Feature Selection: The feature with the highest test accuracy is selected, and its name and score are stored in best_predictive_feature.\nExpected Results\nBased on the dataset’s characteristics:\n\nPotassium (K): Likely the best predictor due to its wide range (5–205) and distinct crop-specific values (e.g., apples: 195–205, oranges: 5–15, chickpeas: 75–85). Expected accuracy: ~0.3–0.4, as single-feature models for 22 classes typically have modest performance due to class overlap.\nPhosphorous (P): Strong but slightly less discriminative (e.g., chickpeas: 55–85, rice: 35–60). Expected accuracy: slightly lower than K.\nNitrogen (N): Moderate performance due to overlapping ranges (e.g., rice: 60–99, maize: 60–100). Expected accuracy: ~0.2–0.3.\npH: Likely the weakest predictor due to similar pH tolerances across crops (5.5–7.5). Expected accuracy: ~0.1–0.2.\nThe classification report will show:\n\nPrecision: Proportion of correct positive predictions per class.\nRecall: Proportion of actual positives correctly identified per class.\nF1-score: Harmonic mean of precision and recall, weighted by class support.\nFor crops with distinct feature values (e.g., apples for K), metrics will be higher; for overlapping ranges (e.g., rice and maize for N), metrics will be lower.\nHypothetical Output\nAssuming K performs best due to its discriminative power:","metadata":{},"cell_type":"markdown","id":"50d7dd03-4686-47dc-990e-baaaf1ab198f"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}